{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores feature engineering for text classification.  Your task is to create two new feature functions (like `dictionary_feature` and `unigram_feature` below), and include them in the `build_features` function.  A check grade will be given to generic features that apply across arbitrary text classification problems (e.g., a feature for bigrams); check+ will be given for at least one feature that reveals your own understanding of the data. What features do you think will help for your particular problem? Your grade is *not* tied to whether accuracy goes up or down, so be creative!  You are free to read in any other external resources you like (dictionaries, document metadata, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are free to use any of the following datasets for this exercise, or to use your own (if you have your own labeled data, I would encourage you to use it!).  If you use your own data, just be sure to format it like the examples below; each directory has a `train.tsv`, `dev.tsv` and `test.tsv` file, where each file is tab-separated (label in the first column and text in the second column).\n",
    "\n",
    "* [Sentiment Analysis](https://ai.stanford.edu/~amaas/data/sentiment/) (Positive/Negative): `data/lmrd`\n",
    "* [Congressional Speech](https://www.cs.cornell.edu/home/llee/data/convote.html) (Democrat/Republican): `data/convote`\n",
    "* Library of Congress Subject Classication ([21 categories](https://en.wikipedia.org/wiki/Library_of_Congress_Classification)): `data/loc`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q0**: Briefly describe your data (including the categories you're predicting).  If you're using your own data, tell us about it; if you're using one of the datasets above, tell us something that shows you've looked at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of movie reviews obtained from IMDB and a respective column with their binary sentiment analysis, defined as either 'positive' or 'negative'. According to the description of the dataset, it contains 50,000 reviews split evenly into half (25k as train data and 25k as test data). Additionally, the dataset seems to be balanced, since the overall distribution of labels is also 25k positive and 25k negative sentiments. \n",
    "This binary sentiment is exactly the category we are trying to predict with our model. However, one of the challenges is that lots of these reviews are extensive and involve more than just a quality analysis of the movie, many times offering some kind of summary and storyline discussion and inclinations towards specific actors and actresses. For example: \n",
    "\n",
    "*``The movie Titanic makes it much more then just a  \"night to remember\" . It re writes a tragic history event that will always be talked about and will never been forgotten . Why so criticised ? I have no idea . Could/will they ever make a movie like Titanic that is so moving and touching every time you watch it . Could they ever replace such an epic masterpiece . It will be almost impossible . The director no doubt had the major impact on the film . A simple disaster film ( boring to watch ) converted to an unbelievable romance . Yes I 'm not the Romance type either , but that should not bother you , because you will never see a romance like this . Guaranteed ! Everything to the amazing effects , to the music , to the sublime acting . The movie creates an amazing visual and a wonderful feeling . Everything looks very real and live . The legend herself \"TITANIC\" is shown brilliantly in all classes , too looks , too accommodation . The acting was the real effect . Dicaprio and Winslet are simply the best at playing there roles . No one could have done better . They are partly the reason why the film is so great . I guess it 's not too much to talk about . The plot is simple , The acting is brilliant , based on a true story , Probably more then half of the consumers that watch the film will share tears , thanks to un imaginable ending which can never be forgotten . Well if you have n't seen this film your missing out on something Hesterical , and a film to idolise for Hollywood . Could it get better ? No . Not at all . The most moving film of all time , do n't listen to people , see for yourself then you will understand . A landmark . ( do n't be surprised if you cry too )\"``\n",
    "\n",
    "Therefore, as presented below, in one of my features, I will try to take advantage of that review writing style to verify if there is a way to predict its sentiment based on the names of the actors mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "import operator\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from math import sqrt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_old(filename):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            label=cols[0]\n",
    "            text=word_tokenize(cols[1])\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, maximum_data_points = 1000):\n",
    "    X = []\n",
    "    Y = []\n",
    "    data_count = 0  # Counter for the number of data points read\n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if data_count >= maximum_data_points:\n",
    "                break  # Exit the loop if the maximum number of data points is reached\n",
    "\n",
    "            cols = line.rstrip().split(\"\\t\")\n",
    "            label = cols[0]\n",
    "            text = word_tokenize(cols[1])\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "            data_count += 1  # Increment the data point counter\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the directory with the data you will be using.\n",
    "# The directory should contain train.tsv, dev.tsv and test.tsv\n",
    "directory=\"../data/lmrd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY=read_data(\"%s/train.tsv\" % directory, maximum_data_points=1000)\n",
    "devX, devY=read_data(\"%s/dev.tsv\" % directory, maximum_data_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(trainY, devY):\n",
    "    labelCounts=Counter()\n",
    "    for label in trainY:\n",
    "        labelCounts[label]+=1\n",
    "    majority=labelCounts.most_common(1)[0][0]\n",
    "    \n",
    "    correct=0.\n",
    "    for label in devY:\n",
    "        if label == majority:\n",
    "            correct+=1\n",
    "            \n",
    "    print(\"%s\\t%.3f\" % (majority, correct/len(devY)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll create two feature classes -- one feature class noting the presence of a word in an external dictionary, and one feature class for the word identity (i.e., unigram).  We'll implement each feature class as a function that takes a single document as input (as a list of tokens) and returns a dict corresponding to the feature we're creating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a sample dictionary if we were using the convote political data\n",
    "dem_dictionary=set([\"republican\",\"cut\", \"opposition\"])\n",
    "repub_dictionary=set([\"growth\",\"economy\"])\n",
    "\n",
    "def political_dictionary_feature(tokens):\n",
    "    feats={}\n",
    "    for word in tokens:\n",
    "        if word in dem_dictionary:\n",
    "            feats[\"word_in_dem_dictionary\"]=1\n",
    "        if word in repub_dictionary:\n",
    "            feats[\"word_in_repub_dictionary\"]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_feature(tokens):\n",
    "    feats={}\n",
    "    for word in tokens:\n",
    "        feats[\"UNIGRAM_%s\" % word]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Add first new feature function here.  Describe your feature and why you think it will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic bigrams feature that could be applicable across arbitrary texts\n",
    "def new_feature_class_one(tokens):\n",
    "    feats = {}\n",
    "    for i in range(len(tokens) - 1):\n",
    "        bigram = f\"BIGRAM_{tokens[i]}_{tokens[i + 1]}\"\n",
    "        feats[bigram] = 1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**: Add second new feature function here. Describe your feature and why you think it will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the IMDB reviews, I could notice that many of those reviews also included some kind of brief summary of the movie, or comments related to the actual storyline and not only the quality of the movie. So, I would expect that some of the sentiment scores could be related not only the movie quality but also if the movie is a happy versus sad movie. Therefore, I am proposing a check on name of actors and actresses that are associated with either happy or sad movies in the comments and using that as a feature.\n",
    "#Specific dictionary analysis using as reference samples of lists of the funniest actors and actresses (https://www.imdb.com/list/ls051583078/; https://www.imdb.com/list/ls062039274/) and samples from lists of sad-movies actors/actresses (https://www.therichest.com/expensive-lifestyle/10-male-actors-who-always-cry-in-their-movies/; https://www.buzzfeed.com/noradominick/actors-amazing-performances-sad-tv-scenes)\n",
    "sad_movies_actors_and_actresses = [\"hanks\", \"dicaprio\", \"depp\", \"phoenix\", \"crowe\", \"streep\", \"blanchett\", \"kidman\", \"theron\", \"moore\"]\n",
    "happy_movies_actors_and_actresses = [\"ferrell\", \"carrey\", \"sandler\", \"pratt\", \"johnson\", \"witherspoon\", \"aniston\", \"bullock\", \"adams\", \"roberts\"]\n",
    "\n",
    "\n",
    "def new_feature_class_two(tokens):\n",
    "    feats={}\n",
    "    for name in tokens:\n",
    "        if name in sad_movies_actors_and_actresses:\n",
    "            feats[\"name_in_sad_movie_dictionary\"]=1\n",
    "        if name in happy_movies_actors_and_actresses:\n",
    "            feats[\"name_in_happy_movie_dictionary\"]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main function we'll use to aggregate together all of the information from different feature classes.  Each document has a feature dict (`feats`), and we'll update that dict with the new dict that each separate feature class is returning.  (Here you want to make sure that the keys each feature function is creating are unique so they don't get clobbered by other functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(trainX, feature_functions):\n",
    "    data=[]\n",
    "    for tokens in trainX:\n",
    "        feats={}\n",
    "\n",
    "        for function in feature_functions:\n",
    "            feats.update(function(tokens))\n",
    "\n",
    "        data.append(feats)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper function converts a dictionary of feature names to unique numerical ids\n",
    "def create_vocab(data):\n",
    "    feature_vocab={}\n",
    "    idx=0\n",
    "    for doc in data:\n",
    "        for feat in doc:\n",
    "            if feat not in feature_vocab:\n",
    "                feature_vocab[feat]=idx\n",
    "                idx+=1\n",
    "                \n",
    "    return feature_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper function converts a dictionary of feature names to a sparse representation\n",
    "# that we can fit in a scikit-learn model.  This is important because almost all feature \n",
    "# values will be 0 for most documents (note: why?), and we don't want to save them all in \n",
    "# memory.\n",
    "\n",
    "def features_to_ids(data, feature_vocab):\n",
    "    new_data=sparse.lil_matrix((len(data), len(feature_vocab)))\n",
    "    for idx,doc in enumerate(data):\n",
    "        for f in doc:\n",
    "            if f in feature_vocab:\n",
    "                new_data[idx,feature_vocab[f]]=doc[f]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates a list of feature functions on the training/dev data arguments\n",
    "def pipeline(trainX, devX, trainY, devY, feature_functions):\n",
    "    trainX_feat=build_features(trainX, feature_functions)\n",
    "    devX_feat=build_features(devX, feature_functions)\n",
    "\n",
    "    # just create vocabulary from features in *training* data\n",
    "    feature_vocab=create_vocab(trainX_feat)\n",
    "\n",
    "    trainX_ids=features_to_ids(trainX_feat, feature_vocab)\n",
    "    devX_ids=features_to_ids(devX_feat, feature_vocab)\n",
    "    \n",
    "    logreg = linear_model.LogisticRegression(C=1.0, solver='lbfgs', penalty='l2', max_iter=10000)\n",
    "    logreg.fit(trainX_ids, trainY)\n",
    "    print(\"Accuracy: %.3f\" % logreg.score(devX_ids, devY)) \n",
    "    return logreg, feature_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(clf, vocab, n=10):\n",
    "\n",
    "    reverse_vocab=[None]*len(clf.coef_[0])\n",
    "    for k in vocab:\n",
    "        reverse_vocab[vocab[k]]=k\n",
    "\n",
    "    if len(clf.classes_) == 2:\n",
    "        \n",
    "        weights=clf.coef_[0]\n",
    "        for feature, weight in sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))[:n]:\n",
    "            print(\"%.3f\\t%s\" % (weight, feature))\n",
    "\n",
    "        print()\n",
    "\n",
    "        for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "            print(\"%.3f\\t%s\" % (weight, feature))\n",
    "\n",
    "    else:  \n",
    "        for i, cat in enumerate(clf.classes_):\n",
    "\n",
    "            weights=clf.coef_[i]\n",
    "\n",
    "            for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\t0.500\n"
     ]
    }
   ],
   "source": [
    "majority_class(trainY,devY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the impact of different feature functions by evaluating them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "features=[unigram_feature]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF you want to print the coefficients for any of the models you train, you can do so like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.314\tUNIGRAM_worst\n",
      "-0.995\tUNIGRAM_bad\n",
      "-0.854\tUNIGRAM_waste\n",
      "-0.629\tUNIGRAM_just\n",
      "-0.617\tUNIGRAM_?\n",
      "-0.569\tUNIGRAM_awful\n",
      "-0.560\tUNIGRAM_free\n",
      "-0.555\tUNIGRAM_looking\n",
      "-0.547\tUNIGRAM_dull\n",
      "-0.533\tUNIGRAM_disappointing\n",
      "\n",
      "0.902\tUNIGRAM_love\n",
      "0.699\tUNIGRAM_wonderful\n",
      "0.684\tUNIGRAM_everyone\n",
      "0.684\tUNIGRAM_very\n",
      "0.646\tUNIGRAM_loved\n",
      "0.615\tUNIGRAM_excellent\n",
      "0.588\tUNIGRAM_well\n",
      "0.565\tUNIGRAM_first\n",
      "0.534\tUNIGRAM_My\n",
      "0.520\tUNIGRAM_always\n"
     ]
    }
   ],
   "source": [
    "print_weights(clf, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'political_dictionary_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features\u001b[38;5;241m=\u001b[39m[\u001b[43mpolitical_dictionary_feature\u001b[49m, unigram_feature]\n\u001b[1;32m      2\u001b[0m clf, vocab\u001b[38;5;241m=\u001b[39mpipeline(trainX, devX, trainY, devY, features)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'political_dictionary_feature' is not defined"
     ]
    }
   ],
   "source": [
    "features=[political_dictionary_feature, unigram_feature]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.771\n"
     ]
    }
   ],
   "source": [
    "features=[new_feature_class_one]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "features=[new_feature_class_two]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806\n"
     ]
    }
   ],
   "source": [
    "features=[new_feature_class_two, unigram_feature]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.771\n"
     ]
    }
   ],
   "source": [
    "features=[new_feature_class_one, new_feature_class_two]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "features=[unigram_feature, new_feature_class_one, new_feature_class_two]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
